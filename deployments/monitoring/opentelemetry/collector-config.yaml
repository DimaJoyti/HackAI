apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: monitoring
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/component: config
data:
  collector.yaml: |
    receivers:
      # OTLP receiver for traces, metrics, and logs
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      
      # Prometheus receiver for scraping metrics
      prometheus:
        config:
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
          scrape_configs:
            - job_name: 'kubernetes-pods'
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                  action: keep
                  regex: true
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                  action: replace
                  target_label: __metrics_path__
                  regex: (.+)
                - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                  action: replace
                  regex: ([^:]+)(?::\d+)?;(\d+)
                  replacement: $1:$2
                  target_label: __address__
                - action: labelmap
                  regex: __meta_kubernetes_pod_label_(.+)
                - source_labels: [__meta_kubernetes_namespace]
                  action: replace
                  target_label: kubernetes_namespace
                - source_labels: [__meta_kubernetes_pod_name]
                  action: replace
                  target_label: kubernetes_pod_name
            
            - job_name: 'kubernetes-services'
              kubernetes_sd_configs:
                - role: service
              relabel_configs:
                - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
                  action: keep
                  regex: true
                - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
                  action: replace
                  target_label: __metrics_path__
                  regex: (.+)
                - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
                  action: replace
                  regex: ([^:]+)(?::\d+)?;(\d+)
                  replacement: $1:$2
                  target_label: __address__
                - action: labelmap
                  regex: __meta_kubernetes_service_label_(.+)
                - source_labels: [__meta_kubernetes_namespace]
                  action: replace
                  target_label: kubernetes_namespace
                - source_labels: [__meta_kubernetes_service_name]
                  action: replace
                  target_label: kubernetes_service_name
      
      # Jaeger receiver for legacy Jaeger traces
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_http:
            endpoint: 0.0.0.0:14268
          thrift_compact:
            endpoint: 0.0.0.0:6831
          thrift_binary:
            endpoint: 0.0.0.0:6832
      
      # Zipkin receiver
      zipkin:
        endpoint: 0.0.0.0:9411
      
      # Kubernetes cluster receiver for cluster-level metrics
      k8s_cluster:
        auth_type: serviceAccount
        node_conditions_to_report: [Ready, MemoryPressure, DiskPressure, PIDPressure]
        allocatable_types_to_report: [cpu, memory, storage]
      
      # Kubelet stats receiver
      kubeletstats:
        collection_interval: 20s
        auth_type: serviceAccount
        endpoint: ${KUBE_NODE_NAME}:10250
        insecure_skip_verify: true
        metric_groups:
          - node
          - pod
          - container
          - volume
      
      # Host metrics receiver
      hostmetrics:
        collection_interval: 30s
        scrapers:
          cpu:
            metrics:
              system.cpu.utilization:
                enabled: true
          disk:
          filesystem:
            metrics:
              system.filesystem.utilization:
                enabled: true
          load:
          memory:
            metrics:
              system.memory.utilization:
                enabled: true
          network:
          paging:
          processes:
          process:
            mute_process_name_error: true

    processors:
      # Batch processor for better performance
      batch:
        timeout: 1s
        send_batch_size: 1024
        send_batch_max_size: 2048
      
      # Memory limiter to prevent OOM
      memory_limiter:
        limit_mib: 512
        spike_limit_mib: 128
        check_interval: 5s
      
      # Resource processor to add/modify resource attributes
      resource:
        attributes:
          - key: cloud.provider
            value: ${CLOUD_PROVIDER}
            action: upsert
          - key: cloud.region
            value: ${CLOUD_REGION}
            action: upsert
          - key: k8s.cluster.name
            value: ${K8S_CLUSTER_NAME}
            action: upsert
          - key: deployment.environment
            value: ${ENVIRONMENT}
            action: upsert
      
      # Attributes processor for span/metric attributes
      attributes:
        actions:
          - key: http.user_agent
            action: delete
          - key: http.request.header.authorization
            action: delete
          - key: sensitive_data
            action: delete
      
      # Probabilistic sampler for traces
      probabilistic_sampler:
        sampling_percentage: 10.0
      
      # Tail sampling processor for intelligent sampling
      tail_sampling:
        decision_wait: 10s
        num_traces: 50000
        expected_new_traces_per_sec: 10
        policies:
          - name: errors
            type: status_code
            status_code: {status_codes: [ERROR]}
          - name: slow_requests
            type: latency
            latency: {threshold_ms: 1000}
          - name: random_sampling
            type: probabilistic
            probabilistic: {sampling_percentage: 1.0}
      
      # K8s attributes processor
      k8sattributes:
        auth_type: serviceAccount
        passthrough: false
        filter:
          node_from_env_var: KUBE_NODE_NAME
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
        pod_association:
          - sources:
            - from: resource_attribute
              name: k8s.pod.ip
          - sources:
            - from: resource_attribute
              name: k8s.pod.uid
          - sources:
            - from: connection

    exporters:
      # Prometheus exporter for metrics
      prometheus:
        endpoint: "0.0.0.0:8889"
        namespace: hackai
        const_labels:
          cluster: ${K8S_CLUSTER_NAME}
          environment: ${ENVIRONMENT}
          cloud_provider: ${CLOUD_PROVIDER}
      
      # Jaeger exporter for traces
      jaeger:
        endpoint: jaeger-collector.monitoring.svc.cluster.local:14250
        tls:
          insecure: true
      
      # OTLP exporter for sending to other OTEL collectors
      otlp:
        endpoint: ${OTLP_ENDPOINT}
        tls:
          insecure: true
        headers:
          api-key: ${OTLP_API_KEY}
      
      # Logging exporter for debugging
      logging:
        loglevel: info
        sampling_initial: 5
        sampling_thereafter: 200
      
      # AWS CloudWatch exporter (when running on AWS)
      awscloudwatchmetrics:
        region: ${AWS_REGION}
        namespace: HackAI/MultiCloud
        dimension_rollup_option: NoDimensionRollup
        metric_declarations:
          - dimensions: [[service.name], [service.name, service.version]]
            metric_name_selectors:
              - ".*"
      
      # Google Cloud Monitoring exporter (when running on GCP)
      googlecloud:
        project: ${GCP_PROJECT_ID}
        metric:
          prefix: hackai.
        trace:
          bundle_delay_threshold: 2s
      
      # Azure Monitor exporter (when running on Azure)
      azuremonitor:
        instrumentation_key: ${AZURE_INSTRUMENTATION_KEY}
        maxbatchsize: 100
        maxbatchinterval: 10s

    extensions:
      # Health check extension
      health_check:
        endpoint: 0.0.0.0:13133
      
      # pprof extension for performance profiling
      pprof:
        endpoint: 0.0.0.0:1777
      
      # zpages extension for debugging
      zpages:
        endpoint: 0.0.0.0:55679

    service:
      extensions: [health_check, pprof, zpages]
      
      pipelines:
        # Traces pipeline
        traces:
          receivers: [otlp, jaeger, zipkin]
          processors: [memory_limiter, resource, k8sattributes, attributes, tail_sampling, batch]
          exporters: [jaeger, otlp, logging]
        
        # Metrics pipeline
        metrics:
          receivers: [otlp, prometheus, k8s_cluster, kubeletstats, hostmetrics]
          processors: [memory_limiter, resource, k8sattributes, batch]
          exporters: [prometheus, awscloudwatchmetrics, googlecloud, azuremonitor, logging]
        
        # Logs pipeline
        logs:
          receivers: [otlp]
          processors: [memory_limiter, resource, k8sattributes, attributes, batch]
          exporters: [logging]

      telemetry:
        logs:
          level: "info"
        metrics:
          address: 0.0.0.0:8888
          level: detailed
        traces:
          processors:
            - batch

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: monitoring
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/component: collector
spec:
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: opentelemetry-collector
      app.kubernetes.io/component: collector
  template:
    metadata:
      labels:
        app.kubernetes.io/name: opentelemetry-collector
        app.kubernetes.io/component: collector
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8889"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: otel-collector
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:0.89.0
        command:
          - "/otelcol-contrib"
          - "--config=/conf/collector.yaml"
        env:
        - name: KUBE_NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        - name: K8S_CLUSTER_NAME
          value: "hackai-production"
        - name: ENVIRONMENT
          value: "production"
        - name: CLOUD_PROVIDER
          value: "multi-cloud"
        - name: CLOUD_REGION
          value: "us-west-2"
        - name: OTLP_ENDPOINT
          value: "https://api.honeycomb.io"
        - name: OTLP_API_KEY
          valueFrom:
            secretKeyRef:
              name: otel-secrets
              key: honeycomb-api-key
        - name: AWS_REGION
          value: "us-west-2"
        - name: GCP_PROJECT_ID
          value: "hackai-production"
        - name: AZURE_INSTRUMENTATION_KEY
          valueFrom:
            secretKeyRef:
              name: otel-secrets
              key: azure-instrumentation-key
        ports:
        - containerPort: 4317
          name: otlp-grpc
          protocol: TCP
        - containerPort: 4318
          name: otlp-http
          protocol: TCP
        - containerPort: 8889
          name: prometheus
          protocol: TCP
        - containerPort: 13133
          name: health
          protocol: TCP
        - containerPort: 14250
          name: jaeger-grpc
          protocol: TCP
        - containerPort: 14268
          name: jaeger-http
          protocol: TCP
        - containerPort: 9411
          name: zipkin
          protocol: TCP
        volumeMounts:
        - name: config
          mountPath: /conf
          readOnly: true
        livenessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 5
          periodSeconds: 10
        resources:
          requests:
            memory: 256Mi
            cpu: 200m
          limits:
            memory: 512Mi
            cpu: 500m
      volumes:
      - name: config
        configMap:
          name: otel-collector-config
          items:
          - key: collector.yaml
            path: collector.yaml
